{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b8af8e",
   "metadata": {},
   "source": [
    "#### Se utilizó el cuaderno Representaciones_distribuidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7ce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el corpus\n",
    "with open(\"../data/corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texto = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cb9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus tokenizado: 379598 tokens\n",
      "Tokens: ['capítulo', 'primero', 'que', 'trata', 'de', 'la', 'condición', 'y', 'ejercicio', 'del']\n"
     ]
    }
   ],
   "source": [
    "# Realizamos la tokenizacion\n",
    "tokens = texto.split()\n",
    "print(f\"Corpus tokenizado: {len(tokens)} tokens\")\n",
    "print(\"Tokens:\", tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a763bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 22904\n"
     ]
    }
   ],
   "source": [
    "# Construimos el vocabulario\n",
    "vocab = sorted(set(tokens))\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "V = len(vocab)\n",
    "print(f\"Tamaño del vocabulario: {V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd34507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_pares_skipgram(tokens, window_size=2):\n",
    "    pares = []\n",
    "    for idx, target_word in enumerate(tokens):\n",
    "        start = max(0, idx - window_size)\n",
    "        end = min(len(tokens), idx + window_size + 1)\n",
    "        for context_idx in range(start, end):\n",
    "            if context_idx != idx:\n",
    "                pares.append((target_word, tokens[context_idx]))\n",
    "    return pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049fbbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares generados: 1518386\n",
      "Ejemplo de 10 pares: [('capítulo', 'primero'), ('capítulo', 'que'), ('primero', 'capítulo'), ('primero', 'que'), ('primero', 'trata'), ('que', 'capítulo'), ('que', 'primero'), ('que', 'trata'), ('que', 'de'), ('trata', 'primero')]\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "pares = generar_pares_skipgram(tokens, window_size=window_size)\n",
    "print(f\"Pares generados: {len(pares)}\")\n",
    "print(\"Ejemplo de 10 pares:\", pares[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601463de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir pares a indices\n",
    "pares_idx = [(word_to_ix[t], word_to_ix[c]) for t, c in pares]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9ccfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
