{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b8af8e",
   "metadata": {},
   "source": [
    "#### Se utilizó el cuaderno Representaciones_distribuidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c9e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab5733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from preprocesamiento import tokenizar, construir_vocabulario, generar_pares_skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb7ce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el corpus\n",
    "with open(\"../data/corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texto = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99cb9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus tokenizado: 379598 tokens\n",
      "Tokens: ['capítulo', 'primero', 'que', 'trata', 'de', 'la', 'condición', 'y', 'ejercicio', 'del']\n"
     ]
    }
   ],
   "source": [
    "# Realizamos la tokenizacion\n",
    "tokens = tokenizar(texto)\n",
    "print(f\"Corpus tokenizado: {len(tokens)} tokens\")\n",
    "print(\"Tokens:\", tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8a763bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 22904\n"
     ]
    }
   ],
   "source": [
    "# Construimos el vocabulario\n",
    "vocab, word_to_ix, ix_to_word = construir_vocabulario(tokens)\n",
    "V = len(vocab)\n",
    "print(f\"Tamaño del vocabulario: {V}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "049fbbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pares generados: 1518386\n",
      "Ejemplo de 10 pares: [('capítulo', 'primero'), ('capítulo', 'que'), ('primero', 'capítulo'), ('primero', 'que'), ('primero', 'trata'), ('que', 'capítulo'), ('que', 'primero'), ('que', 'trata'), ('que', 'de'), ('trata', 'primero')]\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "pares = generar_pares_skipgram(tokens, window_size)\n",
    "print(f\"Pares generados: {len(pares)}\")\n",
    "print(\"Ejemplo de 10 pares:\", pares[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9fcf8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de 10 pares: [(3860, 17146), (3860, 17612), (17146, 3860), (17146, 17612), (17146, 21372), (17612, 3860), (17612, 17146), (17612, 21372), (17612, 6137), (21372, 17146)]\n"
     ]
    }
   ],
   "source": [
    "#Convertir pares a indices\n",
    "pares_idx = [(word_to_ix[t], word_to_ix[c]) for t, c in pares]\n",
    "print(\"Ejemplo de 10 pares:\", pares_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6b738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
